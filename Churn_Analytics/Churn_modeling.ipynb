{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "basetable = pd.read_csv('basetable_churn.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXTRELNO</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Recency</th>\n",
       "      <th>Total_Monetary</th>\n",
       "      <th>Average_Monetary</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>used_order</th>\n",
       "      <th>used_initiative</th>\n",
       "      <th>used_bank</th>\n",
       "      <th>used_unknown</th>\n",
       "      <th>medium_cat_electronic</th>\n",
       "      <th>medium_cat_face_to_face</th>\n",
       "      <th>medium_cat_paper</th>\n",
       "      <th>medium_cat_unknown</th>\n",
       "      <th>complaint</th>\n",
       "      <th>Incoming</th>\n",
       "      <th>Outgoing</th>\n",
       "      <th>comu_count</th>\n",
       "      <th>LANGUACODE</th>\n",
       "      <th>province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26414</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2786.13</td>\n",
       "      <td>19.900929</td>\n",
       "      <td>140</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>NL</td>\n",
       "      <td>West Flanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26419</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3108.99</td>\n",
       "      <td>56.527091</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>NL</td>\n",
       "      <td>Antwerp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26430</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2828.28</td>\n",
       "      <td>19.917465</td>\n",
       "      <td>142</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>NL</td>\n",
       "      <td>Antwerp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26430</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2828.28</td>\n",
       "      <td>19.917465</td>\n",
       "      <td>142</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>NL</td>\n",
       "      <td>Antwerp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26431</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>3294.57</td>\n",
       "      <td>205.910625</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>NL</td>\n",
       "      <td>West Flanders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXTRELNO  Churn  Recency  Total_Monetary  Average_Monetary  Frequency  \\\n",
       "0     26414      0       15         2786.13         19.900929        140   \n",
       "1     26419      0       29         3108.99         56.527091         55   \n",
       "2     26430      1       15         2828.28         19.917465        142   \n",
       "3     26430      0       15         2828.28         19.917465        142   \n",
       "4     26431      0      190         3294.57        205.910625         16   \n",
       "\n",
       "   used_order  used_initiative  used_bank  used_unknown  \\\n",
       "0         138                0          0             2   \n",
       "1           0                2         48             5   \n",
       "2         137                0          3             2   \n",
       "3         137                0          3             2   \n",
       "4           0                0         13             3   \n",
       "\n",
       "   medium_cat_electronic  medium_cat_face_to_face  medium_cat_paper  \\\n",
       "0                      2                        0                19   \n",
       "1                      5                        0                19   \n",
       "2                      2                        0                21   \n",
       "3                      2                        0                21   \n",
       "4                      1                        0                18   \n",
       "\n",
       "   medium_cat_unknown  complaint  Incoming  Outgoing  comu_count LANGUACODE  \\\n",
       "0                  32          0         1        52          53         NL   \n",
       "1                  32          0         1        55          56         NL   \n",
       "2                  33          1         1        55          56         NL   \n",
       "3                  33          1         1        55          56         NL   \n",
       "4                  33          0         0        52          52         NL   \n",
       "\n",
       "        province  \n",
       "0  West Flanders  \n",
       "1        Antwerp  \n",
       "2        Antwerp  \n",
       "3        Antwerp  \n",
       "4  West Flanders  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXTRELNO                     int64\n",
       "Churn                        int64\n",
       "Recency                      int64\n",
       "Total_Monetary             float64\n",
       "Average_Monetary           float64\n",
       "Frequency                    int64\n",
       "used_order                   int64\n",
       "used_initiative              int64\n",
       "used_bank                    int64\n",
       "used_unknown                 int64\n",
       "medium_cat_electronic        int64\n",
       "medium_cat_face_to_face      int64\n",
       "medium_cat_paper             int64\n",
       "medium_cat_unknown           int64\n",
       "complaint                    int64\n",
       "Incoming                     int64\n",
       "Outgoing                     int64\n",
       "comu_count                   int64\n",
       "LANGUACODE                  object\n",
       "province                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "1. split train, val and test data set\n",
    "2. Missing value\n",
    "3. Catergorical variables encoder\n",
    "4. Numerical variables standarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split train, val and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set\n",
    "train, val_test = train_test_split(basetable, test_size=0.3, random_state=42)\n",
    "# split val and test \n",
    "val,test = train_test_split(val_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6474, 20)\n",
      "(1387, 20)\n",
      "(1388, 20)\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXTRELNO                   0\n",
       "Churn                      0\n",
       "Recency                    0\n",
       "Total_Monetary             0\n",
       "Average_Monetary           0\n",
       "Frequency                  0\n",
       "used_order                 0\n",
       "used_initiative            0\n",
       "used_bank                  0\n",
       "used_unknown               0\n",
       "medium_cat_electronic      0\n",
       "medium_cat_face_to_face    0\n",
       "medium_cat_paper           0\n",
       "medium_cat_unknown         0\n",
       "complaint                  0\n",
       "Incoming                   0\n",
       "Outgoing                   0\n",
       "comu_count                 0\n",
       "LANGUACODE                 0\n",
       "province                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing value\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXTRELNO                   0\n",
       "Churn                      0\n",
       "Recency                    0\n",
       "Total_Monetary             0\n",
       "Average_Monetary           0\n",
       "Frequency                  0\n",
       "used_order                 0\n",
       "used_initiative            0\n",
       "used_bank                  0\n",
       "used_unknown               0\n",
       "medium_cat_electronic      0\n",
       "medium_cat_face_to_face    0\n",
       "medium_cat_paper           0\n",
       "medium_cat_unknown         0\n",
       "complaint                  0\n",
       "Incoming                   0\n",
       "Outgoing                   0\n",
       "comu_count                 0\n",
       "LANGUACODE                 0\n",
       "province                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXTRELNO                   0\n",
       "Churn                      0\n",
       "Recency                    0\n",
       "Total_Monetary             0\n",
       "Average_Monetary           0\n",
       "Frequency                  0\n",
       "used_order                 0\n",
       "used_initiative            0\n",
       "used_bank                  0\n",
       "used_unknown               0\n",
       "medium_cat_electronic      0\n",
       "medium_cat_face_to_face    0\n",
       "medium_cat_paper           0\n",
       "medium_cat_unknown         0\n",
       "complaint                  0\n",
       "Incoming                   0\n",
       "Outgoing                   0\n",
       "comu_count                 0\n",
       "LANGUACODE                 0\n",
       "province                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode lanuagecode and province\n",
    "language_encoder = LabelEncoder()\n",
    "province_encoder = LabelEncoder()\n",
    "\n",
    "language_encoder = language_encoder.fit(train['LANGUACODE'])\n",
    "province_encoder = province_encoder.fit(train['province'])\n",
    "\n",
    "train['LANGUACODE'] = language_encoder.transform(train['LANGUACODE'])\n",
    "val['LANGUACODE'] = language_encoder.transform(val['LANGUACODE'])\n",
    "test['LANGUACODE'] = language_encoder.transform(test['LANGUACODE'])\n",
    "\n",
    "train['province'] = province_encoder.transform(train['province'])\n",
    "val['province'] = province_encoder.transform(val['province'])\n",
    "test['province'] = province_encoder.transform(test['province'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Standarized numerical variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EXTRELNO', 'Churn', 'Recency', 'Total_Monetary', 'Average_Monetary',\n",
       "       'Frequency', 'used_order', 'used_initiative', 'used_bank',\n",
       "       'used_unknown', 'medium_cat_electronic', 'medium_cat_face_to_face',\n",
       "       'medium_cat_paper', 'medium_cat_unknown', 'complaint', 'Incoming',\n",
       "       'Outgoing', 'comu_count', 'LANGUACODE', 'province'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop categorical variables\n",
    "numerical_columns = [col for col in train.columns if col not in ['EXTRELNO', 'Churn', 'LANGUACODE', 'province']]\n",
    "\n",
    "# standarized \n",
    "scaler = MinMaxScaler()\n",
    "scaler= scaler.fit(train[numerical_columns])\n",
    "\n",
    "train[numerical_columns] = scaler.transform(train[numerical_columns])\n",
    "val[numerical_columns] = scaler.transform(val[numerical_columns])\n",
    "test[numerical_columns] = scaler.transform(test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split independent and dependent variables\n",
    "train_ind = train.drop(columns=['EXTRELNO','Churn'])\n",
    "train_dep = train['Churn']\n",
    "\n",
    "val_ind = val.drop(columns=['EXTRELNO','Churn'])\n",
    "val_dep = val['Churn']\n",
    "\n",
    "test_ind = test.drop(columns=['EXTRELNO','Churn'])\n",
    "test_dep = test['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Churn task is a binary classificaiton task. Thus we can use a range of classifcation methods like\n",
    "1. Logistic regression\n",
    "2. Decison tree\n",
    "3. Random forest\n",
    "4. XGboost\n",
    "5. SVM\n",
    "6. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516943042537851"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(train_ind,train_dep)\n",
    "# predict \n",
    "lr_preds = lr.predict(val_ind)\n",
    "lr_probs = lr.predict_proba(val_ind)   # default threshold = 0.5\n",
    "\n",
    "# evaluate\n",
    "lr_accuracy = accuracy_score(val_dep, lr_preds)\n",
    "lr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516943042537851"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# churn rate\n",
    "churn_rate = lr_probs[:,1]\n",
    "# predition based on threshold\n",
    "lr_prediction = pd.DataFrame(churn_rate).rename(columns={0:'churn_rate'})\n",
    "lr_prediction['prediction'] = np.where(lr_prediction['churn_rate']>0.6,1,0)\n",
    "lr_accuracy_2 = accuracy_score(val_dep, lr_prediction['prediction'])\n",
    "lr_accuracy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8918529199711608"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree\n",
    "dt = DecisionTreeClassifier()\n",
    "# fit model\n",
    "dt = dt.fit(train_ind,train_dep)\n",
    "# prediction\n",
    "dt_preds = dt.predict(val_ind)\n",
    "dt_probs = dt.predict_proba(val_ind)\n",
    "# evaluate\n",
    "dt_accuracy = accuracy_score(val_dep, dt_preds)\n",
    "dt_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9401586157173756"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomforest \n",
    "rf = RandomForestClassifier()\n",
    "# fit\n",
    "rf = rf.fit(train_ind,train_dep)\n",
    "# prediction\n",
    "rf_preds = rf.predict(val_ind)\n",
    "rf_probs = rf.predict_proba(val_ind)\n",
    "# evaluate\n",
    "rf_accuracy = accuracy_score(val_dep, rf_preds)\n",
    "rf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.21961\n",
      "[1]\tvalidation_0-logloss:0.20781\n",
      "[2]\tvalidation_0-logloss:0.19956\n",
      "[3]\tvalidation_0-logloss:0.19345\n",
      "[4]\tvalidation_0-logloss:0.19041\n",
      "[5]\tvalidation_0-logloss:0.18817\n",
      "[6]\tvalidation_0-logloss:0.18739\n",
      "[7]\tvalidation_0-logloss:0.18724\n",
      "[8]\tvalidation_0-logloss:0.18737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9516943042537851"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGboost\n",
    "# Use \"hist\" for constructing the trees, with early stopping enabled.\n",
    "XGb = xgb.XGBClassifier(tree_method=\"hist\", early_stopping_rounds=2)\n",
    "# Fit the model, test sets are used for early stopping.\n",
    "XGb = XGb.fit(train_ind, train_dep, eval_set=[(val_ind, val_dep)])\n",
    "# prediction\n",
    "XGb_preds = XGb.predict(val_ind)\n",
    "XGb_probs = XGb.predict_proba(val_ind)\n",
    "# evaluate\n",
    "XGb_accuracy = accuracy_score(val_dep, XGb_preds)\n",
    "XGb_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516943042537851"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "SVM = LinearSVC()\n",
    "SVM = SVM.fit(train_ind, train_dep)\n",
    "# prediction\n",
    "SVM_preds = SVM.predict(val_ind)\n",
    "# evaluate\n",
    "SVM_accuracy = accuracy_score(val_dep, SVM_preds)\n",
    "SVM_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516943042537851"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP \n",
    "MLP = MLPClassifier()\n",
    "MLP = MLP.fit(train_ind, train_dep)\n",
    "# prediction\n",
    "MLP_preds = MLP.predict(val_ind)\n",
    "MLP_probs = MLP.predict_proba(val_ind)\n",
    "# evaluate\n",
    "MLP_accuracy = accuracy_score(val_dep, MLP_preds)\n",
    "MLP_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, test\n",
    "train, test = train_test_split(basetable,test_size=0.3, random_state=45)\n",
    "\n",
    "# encode lanuagecode and province\n",
    "language_encoder = LabelEncoder()\n",
    "province_encoder = LabelEncoder()\n",
    "\n",
    "language_encoder = language_encoder.fit(train['LANGUACODE'])\n",
    "province_encoder = province_encoder.fit(train['province'])\n",
    "\n",
    "train['LANGUACODE'] = language_encoder.transform(train['LANGUACODE'])\n",
    "test['LANGUACODE'] = language_encoder.transform(test['LANGUACODE'])\n",
    "\n",
    "train['province'] = province_encoder.transform(train['province'])\n",
    "test['province'] = province_encoder.transform(test['province'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop categorical variables\n",
    "numerical_columns = [col for col in train.columns if col not in ['EXTRELNO', 'Churn', 'LANGUACODE', 'province']]\n",
    "\n",
    "# standarized \n",
    "scaler = MinMaxScaler()\n",
    "scaler= scaler.fit(train[numerical_columns])\n",
    "\n",
    "train[numerical_columns] = scaler.transform(train[numerical_columns])\n",
    "test[numerical_columns] = scaler.transform(test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split independent and dependent variables\n",
    "train_ind = train.drop(columns=['EXTRELNO','Churn'])\n",
    "train_dep = train['Churn']\n",
    "\n",
    "test_ind = test.drop(columns=['EXTRELNO','Churn'])\n",
    "test_dep = test['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "lr = LogisticRegression()\n",
    "# hyperparameters\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l1','l2']\n",
    "c_values = [1.0, 0.1, 0.01]\n",
    "# model\n",
    "lr_grid = dict(model = lr, parameters = dict(solver=solvers,penalty=penalty,C=c_values))\n",
    "lr_par = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "\n",
    "# Decison tree\n",
    "dt = DecisionTreeClassifier()\n",
    "# hyperparameters\n",
    "max_depth=[10,15,20]\n",
    "min_samples_split=[2,3,5]\n",
    "max_leaf_nodes=[15,20,50]\n",
    "dt_grid = dict(model = dt, parameters = dict(max_depth=max_depth,min_samples_split=min_samples_split,max_leaf_nodes=max_leaf_nodes))\n",
    "dt_par = dict(max_depth=max_depth,min_samples_split=min_samples_split,max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "n_estimators=[100,150]\n",
    "criterion=['gini']\n",
    "max_depth=[10,20]\n",
    "min_samples_split=[2,3,5]\n",
    "rf_grid = dict(model = rf, parameters = dict(n_estimators=n_estimators,criterion=criterion,max_depth=max_depth,min_samples_split=min_samples_split))\n",
    "rf_par = dict(n_estimators=n_estimators,criterion=criterion,max_depth=max_depth,min_samples_split=min_samples_split)\n",
    "\n",
    "# SVM\n",
    "SVM = LinearSVC()\n",
    "penalty=['l2','l1']\n",
    "loss=['squared_hinge']\n",
    "C=[1.0, 0.1, 0.01]\n",
    "svm_grid = dict(model = SVM, parameters = dict(penalty=penalty,loss=loss,C=C))\n",
    "svm_par = dict(penalty=penalty,loss=loss,C=C)\n",
    "\n",
    "# MLP\n",
    "MLP = MLPClassifier()\n",
    "hidden_layer_sizes=[50,100,150]\n",
    "batch_size=[10, 20]\n",
    "learning_rate=[0.01,0.001,0.05]\n",
    "MLP_grid = dict(model = MLP, parameters = dict(hidden_layer_sizes=hidden_layer_sizes,batch_size=batch_size,learning_rate_init=learning_rate))\n",
    "MLP_par = dict(hidden_layer_sizes=hidden_layer_sizes,batch_size=batch_size,learning_rate_init=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() {'solver': ['newton-cg', 'lbfgs', 'liblinear'], 'penalty': ['l1', 'l2'], 'C': [1.0, 0.1, 0.01]}\n",
      "DecisionTreeClassifier() {'max_depth': [10, 15, 20], 'min_samples_split': [2, 3, 5], 'max_leaf_nodes': [15, 20, 50]}\n",
      "RandomForestClassifier() {'n_estimators': [100, 150], 'criterion': ['gini'], 'max_depth': [10, 20], 'min_samples_split': [2, 3, 5]}\n",
      "LinearSVC() {'penalty': ['l2', 'l1'], 'loss': ['squared_hinge'], 'C': [1.0, 0.1, 0.01]}\n",
      "MLPClassifier() {'hidden_layer_sizes': [50, 100, 150], 'batch_size': [10, 20], 'learning_rate_init': [0.01, 0.001, 0.05]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid = dict(model = [lr,dt,rf,SVM,MLP],parameters = [lr_par,dt_par,rf_par,svm_par,MLP_par])\n",
    "for i in range(0,len(grid['model'])):\n",
    "    print(grid[\"model\"][i],grid[\"parameters\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() 0.9567567567567568\n",
      "DecisionTreeClassifier() 0.9553153153153153\n",
      "RandomForestClassifier() 0.9563963963963964\n",
      "LinearSVC() 0.9567567567567568\n",
      "MLPClassifier() 0.9567567567567568\n"
     ]
    }
   ],
   "source": [
    "# set a loop to run and get the test accuracy\n",
    "grid = dict(model = [lr,dt,rf,SVM,MLP],parameters = [lr_par,dt_par,rf_par,svm_par,MLP_par])\n",
    "for i in range(0,len(grid['model'])):\n",
    "    grid_search = GridSearchCV(estimator= grid[\"model\"][i], param_grid=grid[\"parameters\"][i], n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "    grid_result = grid_search.fit(train_ind, train_dep)\n",
    "    prediction = grid_result.predict(test_ind)\n",
    "    accuracy = accuracy_score(test_dep, prediction)\n",
    "    print(grid[\"model\"][i],accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(penalty='l1', solver='liblinear') {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'} 0.9567567567567568\n",
      "DecisionTreeClassifier(max_depth=10, max_leaf_nodes=15, min_samples_split=3) {'max_depth': 10, 'max_leaf_nodes': 15, 'min_samples_split': 3} 0.9553153153153153\n",
      "RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=150) {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 150} 0.956036036036036\n",
      "LinearSVC() {'C': 1.0, 'loss': 'squared_hinge', 'penalty': 'l2'} 0.9567567567567568\n",
      "MLPClassifier(batch_size=10, hidden_layer_sizes=50) {'batch_size': 10, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001} 0.9567567567567568\n"
     ]
    }
   ],
   "source": [
    "# define a funciton to get the hperparameters\n",
    "def cv(grid, train_ind,train_dep,test_ind,threshold):\n",
    "    cv_model = GridSearchCV(estimator= grid['model'], param_grid=grid[\"parameters\"], n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "    cv_model = cv_model.fit(train_ind, train_dep)\n",
    "\n",
    "    # Get predictions based on probabilities\n",
    "    probabilities = cv_model.predict_proba(test_ind)[:, 1]  # Get probabilities for the positive class\n",
    "    predictions = (probabilities >= threshold).astype(int) \n",
    "\n",
    "    accuracy = accuracy_score(test_dep, predictions)\n",
    "    return cv_model.best_estimator_,cv_model.best_params_,accuracy\n",
    "\n",
    "# run the model\n",
    "parameters= [lr_grid,dt_grid,rf_grid,svm_grid,MLP_grid]\n",
    "for i in parameters:\n",
    "    model, hyperparameters,accuracy = cv(i,train_ind,train_dep,test_ind)\n",
    "    print(model, hyperparameters,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(penalty='l1', solver='liblinear') {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'} 0.9567567567567568\n",
      "DecisionTreeClassifier(max_depth=15, max_leaf_nodes=15, min_samples_split=3) {'max_depth': 15, 'max_leaf_nodes': 15, 'min_samples_split': 3} 0.9553153153153153\n",
      "RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=150) {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 150} 0.956036036036036\n",
      "LinearSVC() {'C': 1.0, 'loss': 'squared_hinge', 'penalty': 'l2'} 0.9567567567567568\n",
      "MLPClassifier(batch_size=10, hidden_layer_sizes=50) {'batch_size': 10, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001} 0.9567567567567568\n"
     ]
    }
   ],
   "source": [
    "# define a funciton to get the hperparameters and define threshold\n",
    "def cv(grid, train_ind,train_dep,test_ind, threshold=0.5):\n",
    "    cv_model = GridSearchCV(estimator= grid['model'], param_grid=grid[\"parameters\"], n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "    cv_model = cv_model.fit(train_ind, train_dep)\n",
    "\n",
    "    # Check if the model supports predict_proba                    SVM has no predict_proba attribute\n",
    "    if hasattr(cv_model.best_estimator_, \"predict_proba\"):\n",
    "        probabilities = cv_model.predict_proba(test_ind)[:, 1]\n",
    "        predictions = (probabilities >= threshold).astype(int)\n",
    "    else:\n",
    "        # If predict_proba is not available, use predict\n",
    "        predictions = cv_model.predict(test_ind)\n",
    "\n",
    "    accuracy = accuracy_score(test_dep, predictions)\n",
    "    return cv_model.best_estimator_,cv_model.best_params_,accuracy\n",
    "\n",
    "# run the model\n",
    "parameters= [lr_grid,dt_grid,rf_grid,svm_grid,MLP_grid]\n",
    "for i in parameters:\n",
    "    model, hyperparameters,accuracy = cv(i,train_ind,train_dep,test_ind)\n",
    "    print(model, hyperparameters,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7718918918918919\n",
      "0.9567567567567568\n",
      "churn_rate        555\n",
      "prediction        555\n",
      "threshold_pred    555\n",
      "dtype: int64\n",
      "churn_rate        0\n",
      "prediction        0\n",
      "threshold_pred    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# define a function\n",
    "# final model\n",
    "final_model = LogisticRegression(penalty='l1', solver='liblinear',C=1.0)\n",
    "\n",
    "# fit model\n",
    "final_model = final_model.fit(train_ind,train_dep)\n",
    "\n",
    "# prediction\n",
    "prediction = final_model.predict(test_ind)\n",
    "probs = final_model.predict_proba(test_ind)\n",
    "\n",
    "# set the threshold by top n %\n",
    "predictions = pd.DataFrame(probs[:,1]).rename(columns={0:'churn_rate'}).sort_values(by=['churn_rate'], ascending= False)\n",
    "\n",
    "highest_prob = predictions.nlargest(round((0.2*len(predictions))), ['churn_rate'])['churn_rate']\n",
    "predictions['prediction'] = np.where(predictions['churn_rate'].isin(highest_prob), 1, 0)\n",
    "nlargest_accuracy = accuracy_score(test_dep,predictions['prediction'] )\n",
    "\n",
    "# set the threshold by threshold \n",
    "predictions['threshold_pred'] = np.where(predictions['churn_rate']>0.1, 1, 0)\n",
    "threshold_accuracy = accuracy_score(test_dep,predictions['threshold_pred'] )\n",
    "\n",
    "print(nlargest_accuracy)\n",
    "print(threshold_accuracy)\n",
    "\n",
    "print(predictions[predictions['prediction']==1].count())\n",
    "print(predictions[predictions['threshold_pred']==1].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    120\n",
       "Churn    120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dep = test_dep.reset_index()\n",
    "test_dep[test_dep['Churn']==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-2.684039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recency</td>\n",
       "      <td>-2.996572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total_Monetary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Average_Monetary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frequency</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>used_order</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>used_initiative</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>used_bank</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>used_unknown</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>medium_cat_electronic</td>\n",
       "      <td>0.482348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>medium_cat_face_to_face</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>medium_cat_paper</td>\n",
       "      <td>-0.468801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>medium_cat_unknown</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>complaint</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Incoming</td>\n",
       "      <td>0.210139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Outgoing</td>\n",
       "      <td>-0.183397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>comu_count</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LANGUACODE</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>province</td>\n",
       "      <td>-0.009820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  Coefficient\n",
       "0                 Intercept    -2.684039\n",
       "1                   Recency    -2.996572\n",
       "2            Total_Monetary     0.000000\n",
       "3          Average_Monetary     0.000000\n",
       "4                 Frequency     0.000000\n",
       "5                used_order     0.000000\n",
       "6           used_initiative     0.000000\n",
       "7                 used_bank     0.000000\n",
       "8              used_unknown     0.000000\n",
       "9     medium_cat_electronic     0.482348\n",
       "10  medium_cat_face_to_face     0.000000\n",
       "11         medium_cat_paper    -0.468801\n",
       "12       medium_cat_unknown     0.000000\n",
       "13                complaint     0.000000\n",
       "14                 Incoming     0.210139\n",
       "15                 Outgoing    -0.183397\n",
       "16               comu_count     0.000000\n",
       "17               LANGUACODE     0.000000\n",
       "18                 province    -0.009820"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature names (column names of train_ind)\n",
    "feature_names = train_ind.columns\n",
    "\n",
    "# Get the coefficients (only for the features used)\n",
    "coefficients = final_model.coef_\n",
    "\n",
    "# Construct the feature coefficients DataFrame\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': list(train_ind.columns),  # Feature names from train_ind\n",
    "    'Coefficient': final_model.coef_.flatten()  # Flatten coefficients if necessary\n",
    "})\n",
    "\n",
    "# Create a DataFrame for the intercept\n",
    "intercept_df = pd.DataFrame({\n",
    "    'Feature': ['Intercept'],  # Add intercept as a feature\n",
    "    'Coefficient': [final_model.intercept_[0]]  # Intercept value\n",
    "})\n",
    "\n",
    "# Concatenate intercept and feature coefficients DataFrames\n",
    "df = pd.concat([intercept_df, coef_df], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn\n",
      "0    6134\n",
      "1     340\n",
      "Name: count, dtype: int64\n",
      "Churn\n",
      "0    2655\n",
      "1     120\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check classes balance\n",
    "print(train['Churn'].value_counts())\n",
    "print(test['Churn'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non churn class(0) is more than teh churn class(1) a lot. This is class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oversampling method to resample the data\n",
    "# SMOTE Oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "train_ind_sample, train_dep_sample = smote.fit_resample(train_ind, train_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    6134\n",
       "1    6134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the balance\n",
    "train_dep_sample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(penalty='l1', solver='liblinear') {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'} 0.44828828828828826\n",
      "DecisionTreeClassifier(max_depth=10, max_leaf_nodes=50) {'max_depth': 10, 'max_leaf_nodes': 50, 'min_samples_split': 2} 0.8854054054054054\n",
      "RandomForestClassifier(max_depth=20, min_samples_split=3) {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 3, 'n_estimators': 100} 0.9405405405405406\n",
      "LinearSVC() {'C': 1.0, 'loss': 'squared_hinge', 'penalty': 'l2'} 0.461981981981982\n",
      "MLPClassifier(batch_size=10, hidden_layer_sizes=150) {'batch_size': 10, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.001} 0.8212612612612613\n"
     ]
    }
   ],
   "source": [
    "# define a funciton to get the hperparameters and define threshold\n",
    "def cv(grid, train_ind,train_dep,test_ind, threshold=0.5):\n",
    "    cv_model = GridSearchCV(estimator= grid['model'], param_grid=grid[\"parameters\"], n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "    cv_model = cv_model.fit(train_ind, train_dep)\n",
    "\n",
    "    # Check if the model supports predict_proba                    SVM has no predict_proba attribute\n",
    "    if hasattr(cv_model.best_estimator_, \"predict_proba\"):\n",
    "        probabilities = cv_model.predict_proba(test_ind)[:, 1]\n",
    "        predictions = (probabilities >= threshold).astype(int)\n",
    "    else:\n",
    "        # If predict_proba is not available, use predict\n",
    "        predictions = cv_model.predict(test_ind)\n",
    "\n",
    "    accuracy = accuracy_score(test_dep, predictions)\n",
    "    return cv_model.best_estimator_,cv_model.best_params_,accuracy\n",
    "\n",
    "# run the model\n",
    "parameters= [lr_grid,dt_grid,rf_grid,svm_grid,MLP_grid]\n",
    "for i in parameters:\n",
    "    model, hyperparameters,accuracy = cv(i,train_ind_sample,train_dep_sample,test_ind,threshold=0.5)\n",
    "    print(model, hyperparameters,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7711711711711712\n",
      "0.9398198198198198\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(criterion='gini', max_depth=20,min_samples_split=2,n_estimators=100)\n",
    "\n",
    "# fit model\n",
    "final_model = final_model.fit(train_ind_sample,train_dep_sample)\n",
    "\n",
    "# prediction\n",
    "prediction = final_model.predict(test_ind)\n",
    "probs = final_model.predict_proba(test_ind)\n",
    "\n",
    "# set the threshold by top n %\n",
    "predictions = pd.DataFrame(probs[:,1]).rename(columns={0:'churn_rate'}).sort_values(by=['churn_rate'], ascending= False)\n",
    "\n",
    "highest_prob = predictions.nlargest(round((0.2*len(predictions))), ['churn_rate'])['churn_rate']     #consider this method to set the threshold because the cost of retention non-churner is less expensive than the cost of the loss a churner's life time value\n",
    "predictions['prediction'] = np.where(predictions['churn_rate'].isin(highest_prob), 1, 0)\n",
    "nlargest_accuracy = accuracy_score(test_dep,predictions['prediction'] )\n",
    "\n",
    "# set the threshold by threshold \n",
    "predictions['threshold_pred'] = np.where(predictions['churn_rate']>0.6, 1, 0)\n",
    "threshold_accuracy = accuracy_score(test_dep,predictions['threshold_pred'] )\n",
    "\n",
    "print(nlargest_accuracy)\n",
    "print(threshold_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn_rate        557\n",
      "prediction        557\n",
      "threshold_pred    557\n",
      "dtype: int64\n",
      "churn_rate        49\n",
      "prediction        49\n",
      "threshold_pred    49\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(predictions[predictions['prediction']==1].count())\n",
    "print(predictions[predictions['threshold_pred']==1].count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
